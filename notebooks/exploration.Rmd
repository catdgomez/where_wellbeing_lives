---
title: "R Notebook"
output: html_notebook
---
Libraries I may use called
```{r}

library(tidyverse)
# install for visualizations 
library(ggplot2)
# install to combine date and time
library(lubridate)
# for melting a df
library(reshape)
library(data.table)
library(dplyr)
# for heatmap
library(gapminder)
# install.packages('reshape2')
# for heatmap
library(reshape2)
library(reshape)
library(tidyr)


```
### Perceived Health Status

Reading in the first dataset, perceived health status.
 
```{r}
perceived_health_status <- read_csv("../data/perceived_health_status.csv")
# dnmk <- read_csv("../data/denmark_only_phs.csv")
# perceived_health_status_once <- read_csv("../data/perceived_health_status_once.csv")

```
Inspecting the denmark only data:

```{r}
# dnmk %>% 
#   filter(Sex == "Total")
```

It appears that then 


Inspecting the perceived health data:

```{r}
perceived_health_status %>% 
  filter(`Reference area` == "Denmark")
```

Inspect original perceived health data:
```{r}
# perceived_health_status_once%>% 
#   filter(`Reference area` == "Denmark")
```
```{r}
perceived_health_status
```


Filtering.

```{r}

perceived_health_status_stripped <- perceived_health_status %>% 
  filter(TIME_PERIOD == 2022) %>% 
  filter(REF_AREA == "AUT") %>% 
  filter(Sex == "Total") %>% 
  filter(Age == "15 years or over")  

perceived_health_status_stripped

```
As it appears that after 2007, the number of observations are more significant in number, I will limit my data to 2007 and later. But, since it appears the number of observations drops off in 2024, I will limit my data to a range of 2007-2023. As well, I want to capture all genders and ages. (Corrected "==" to be "%in%" and that corrected much the problem I was running into.)

```{r}

# input code to limit year range, age range, and gender in perceived health status data

phs <- perceived_health_status %>% 
  filter(TIME_PERIOD %in% c(2007:2023)) %>% 
  filter(Sex == "Total") %>% 
  filter(Age == "15 years or over")

phs

```
It turns out that Denmark's data comes only from a population of 15-24 year old, which would be excluded when I filter for age range collective/Total. (Corrected "==" to be "%in%" which corrected what I was seeing.)

```{r}

# perceived_health_status_once %>% 
#   filter(TIME_PERIOD %in% c(2007:2023)) %>% 
#   filter(Sex == "Total") %>% 
#   filter(AGE == "Y_GE15") 

```

```{r}

# sort(unique(perceived_health_status_once$Age))
# 
# perceived_health_status_once %>% 
#   group_by(AGE) %>%
#   summarize(n=n())

```


Inspect the data for the number of years it covers.

```{r}

barplot(table(perceived_health_status$TIME_PERIOD), main = "number of observations of year in the data")


```

Inspect the data for the number of age categories it covers.
```{r}
barplot(table(perceived_health_status$Age), main = "number of observations of age groups in the data")
```

Inspecting the data for balance in the health status column.

```{r}

phs %>% 
  group_by(HEALTH_STATUS) %>% 
  summarize(n=n())

```

Which countries are most heavily represented in the data? Denmark was selected to be included I will download a Denmark only data and investigate why it is no longer located in this data. 

```{r}

phs %>% 
  group_by(`Reference area`) %>%
  summarize(n=n())

```

```{r}
phs %>% 
  group_by(AGE) %>%
  summarize(n=n())

```

The final state of my Perceived Health Status data will be:
```{r}

phs

```



### Education Levels



Reading in the second dataset, education levels.

```{r}

# education_level <- read_csv("../data/educational_attainment_distribution_age_gender.csv")
# education_levels_defined <- read_csv("../data/educational_attainment_distribution.csv")
education_levels_three <- read_csv("../data/educational_attainment.csv")

```

Early data exploration in the education data

```{r}
el_third <- education_levels_three %>% 
  filter(Sex == "Total") %>% 
  filter(Age == "From 25 to 64 years") %>% 
  filter(TIME_PERIOD == 2010) %>% 
  filter(OBS_STATUS == "A") %>% 
  filter(REF_AREA == "AUT") %>% 
  filter(STATISTICAL_OPERATION == "OBS")

el_third
```


```{r}

# ISCED11A_5T8 = Tertiary education
# ISCED11A_3_4 = Upper secondary or post-secondary non-tertiary education
# ISCED11A_0T2 = Below upper secondary education
education_levels_three

```
Verify that there are simply three categories for the education level attained and  Education attainment level columns
```{r}

sort(unique(education_levels_three$ATTAINMENT_LEV))
sort(unique(education_levels_three$`Educational attainment level`))

```

```{r}
sort(unique(education_levels_three$STATISTICAL_OPERATION))
```
I want to use the observed values and not the standard error values at this time. 
```{r}

education_levels_three %>% 
  filter(STATISTICAL_OPERATION == "OBS")

```

I want to see the representation of countries in the data. Certain countries are significantly under represented.

```{r}
barplot(table(education_levels_three$`Reference area`), main = "number of observations of countries in the data")

```

```{r}
barplot(table(education_levels_three$TIME_PERIOD), main = "number of observations of year in the data")

```

check to see which years are present in the data. Base on the lack of data in the years prior to about 1998, I will limit the dataset to 1998-2024.

```{r}

sort(unique(education_levels_three$TIME_PERIOD))

education_levels_three_time <- education_levels_three %>% 
  filter(TIME_PERIOD %in% c(1998:2024))

```

I would like to discover which of the countries are under represented. 

```{r}
education_levels_three_time %>% 
  group_by(`Reference area`) %>%
  summarize(n=n())
```


I want to drop any countries whose count is less than 1800. 

```{r}

# count the frequency of each country
country_count <- table(education_levels_three_time$`Reference area`)

# I do not want any fewer rows for a country than this
num_in_data <- 1800

# which countries match or exceed that number
countries_to_keep <- names(country_count[country_count > num_in_data])

# filter the dataset to keep only rows of countries who are 
#represented in the data a certain number of times or more
education_levels_three_time_countries <- education_levels_three_time[education_levels_three_time$`Reference area` %in% countries_to_keep, ]

education_levels_three_time_countries 


```

Check out which ages are available to filter by.

```{r}
sort(unique(education_levels_three_time_countries$Age))
```

Check number of times each age range is represented in the data
```{r}

barplot(table(education_levels_three_time_countries$Age), main = "number of observations of age in the data")


```


Filter using all of the methods left that I want to filter by: all genders, ages, as well as only observed data, not the standard error.

```{r}

el <- education_levels_three_time_countries %>% 
  filter(Sex == "Total") %>% 
  filter(Age == "From 25 to 64 years") %>% 
  filter(OBS_STATUS == "A") %>%
  filter(STATISTICAL_OPERATION == "OBS")

```

```{r}
el
```


The final state of my education level data will be:

```{r}

# selected all adults from age, and all genders, and only observed values no standard error values
el[1:2,]

```






### Social and Community connection pulled from the Wellbeing dataset





Reading in the third dataset, social connectedness from the wellbeing dataset.


```{r}

social_wellbeing <- read_csv("../data/social_connection_wellbeing.csv")

```

View the data.
```{r}
social_wellbeing[1:2, ]
```

Inspect the UNIT_MEASURE column's unique values.
```{r}

sort(unique(social_wellbeing$UNIT_MEASURE))

```
```{r}

sort(unique(social_wellbeing$Measure))

```


```{r}

social_wellbeing %>% 
  filter(TIME_PERIOD == 2022) %>% 
  filter(REF_AREA == "AUS") %>% 
  filter(Measure %in% c("Social support", "Lack of social support")) %>% 
  filter(Sex == "Total") %>% 
  filter(Age == "Total") %>% 
  filter(`Education level` == "Total")

```
Assigning filtered dataset to new variable.

```{r}

social_support_or_lack <- social_wellbeing %>% 
  filter(TIME_PERIOD %in% c(2007:2023)) %>% 
  filter(Measure %in% c("Social support", "Lack of social support")) %>% 
  filter(Sex == "Total") %>% 
  filter(Age == "Total") %>% 
  filter(`Education level` == "Total")

social_support_or_lack[1:2, ]

```


```{r}

barplot(table(social_support_or_lack$TIME_PERIOD), main = "frequency of years in the data")

```


```{r}

# find unique values for Measure column
sort(unique(social_wellbeing$Measure))


```
How is satisfaction with personal relationships scored?

```{r}
social_wellbeing %>% 
  filter(Measure == "Satisfaction with personal relationships score less than 5")
```

Inspect which Measures are listed with the 0 to 10 unit measure.

```{r}

social_wellbeing_0_10 <- social_wellbeing %>% 
  filter(UNIT_MEASURE == "0_TO_10")

social_wellbeing_0_10[1:2, ]

```


```{r}

sort(unique(social_wellbeing_0_10$Measure))

```

Limit the data to totals on sex, age, and education, in order to capture a population not a specific group within a population. As well, narrow down the date range and select only the Measures whose unit measure is 0-10. 

```{r}

satisfaction_life_rels <- social_wellbeing %>% 
  filter(TIME_PERIOD %in% c(2007:2023)) %>% 
  filter(Measure %in% c("Life satisfaction", "Satisfaction with personal relationships")) %>% 
  filter(Sex == "Total") %>% 
  filter(Age == "Total") %>% 
  filter(`Education level` == "Total")
  
satisfaction_life_rels[1:2, ]

```
```{r}

barplot(table(satisfaction_life_rels$TIME_PERIOD))

```

Looking into the feeling lonely measure.

```{r}


lonely <- social_wellbeing %>% 
  filter(TIME_PERIOD %in% c(2007:2023)) %>%   
  filter(Measure == "Feeling lonely") %>% 
  filter(Sex == "Total") %>% 
  filter(Age == "Total") %>% 
  filter(`Education level` == "Total")
  
lonely[1:2, ]

```

```{r}
barplot(table(lonely$TIME_PERIOD), main = "how often certain years are rep'd in data")
```

```{r}

num_countries_repd_in_lonely <- lonely %>% 
  group_by(`Reference area`) %>% 
  summarise(n=n())


ctrs_desc <- order(num_countries_repd_in_lonely$n, decreasing = TRUE)

num_countries_repd_in_lonely[ctrs_desc,][1:2, ]


```
```{r}
barplot(table(social_support_or_lack$TIME_PERIOD), main = "how often each year shows up in dataset" )
```
```{r}

social_interactions <- social_wellbeing %>% 
  filter(TIME_PERIOD %in% c(2007:2023)) %>%   
  filter(Measure == "Time spent in social interactions") %>% 
  filter(Sex == "Total") %>% 
  filter(Age == "Total") %>% 
  filter(`Education level` == "Total")

social_interactions[1:2, ]

```
```{r}
barplot(table(social_interactions$TIME_PERIOD))
```
```{r}

social_interactions %>% 
  group_by(`Reference area`) %>% 
  summarise(n=n())

```



The final datasets from wellbeing data I have chosen are as follows:

```{r}

# measured as a percentage fo the adult population and is well represented across all years in selected data 
social_support_or_lack[1:2, ]

# measured as a percentage of the adult population, and is almost exclusively 2018 and 2022
lonely[1:2, ]

# years most represented in the data: 2013, 2018, 2022; it is measured on a 0-10 scale. 
satisfaction_life_rels[1:2, ]

# measured in units of hours per week, across various years, very difficult to compare, I will exclude this data for now
social_interactions[1:2, ]

```





### Safety


Reading in the second dataset, education levels.





```{r}

safety_regions <- read_csv("../data/safety_regions.csv")


```
```{r}
safety <- safety_regions %>% 
  filter(TIME_PERIOD %in% c(2007:2023)) %>% 
  filter(TERRITORIAL_LEVEL == "CTRY") %>% 
  filter(Sex %in% c("Total", "Not applicable")) %>% 
  filter(`Observation status` == "Normal value")

safety[1:2, ]

```
```{r}

barplot(table(safety$OBS_VALUE), main = "frequency of percentage of pop measured unsafe instances in the data")

```


```{r}
sort(unique(safety$`Observation status`))

```

The final dataset from safety data I have chosen are as follows:
```{r}
safety[1:2,]
```

Final datasets are:

```{r}

# perceived health status, subjective survey of good, fair, and bad health
phs[1:2, ]

# selected all adults from age, and all genders, and only observed values no standard error values
el[1:2, ]

# measured as a percentage fo the adult population and is well represented across all years in selected data 
social_support_or_lack[1:2, ]

# measured as a percentage of the adult population, and is almost exclusively 2018 and 2022
lonely[1:2, ]

# years most represented in the data: 2013, 2018, 2022; it is measured on a 0-10 scale. 
satisfaction_life_rels[1:2, ]

# measured in cases per 100,000 persons, well distributed across selected years
safety[1:2,]

```

###Merging data sets together into one

Order the data's country column (REF_AREA) alphabetically. 

```{r}

# Order the data's country column (`Reference area`) alphabetically.

phs_v1 <- phs[order(phs$`Reference area`),] 

el_v1 <- el[order(el$`Reference area`),]

safety_v1 <- safety[order(safety$`Reference area`),]

social_support_or_lack_v1 <- social_support_or_lack[order(social_support_or_lack$`Reference area`),]

lonely_v1 <- lonely[order(lonely$`Reference area`),]

satisfaction_life_rels_v1 <- satisfaction_life_rels[order(satisfaction_life_rels$`Reference area`),]
 


phs_v1 # percentage of the population
el_v1 # percentage of the population
safety_v1 # measured in cases per 100,000 persons
social_support_or_lack_v1 # percentage of the population
lonely_v1 # percentage of the population
satisfaction_life_rels_v1[1:2,]

```

rename columns

```{r}

phs_v2 <- rename(phs_v1, replace = c(`Reference area` = "Reference_area", `Frequency of observation` = "Freq_of_obs_phs", `Unit of measure` = "Unit_of_measure_phs", `Health status` = "Health_status", "OBS_VALUE" = "OBS_VALUE_PHS"))

el_v2 <- rename(el_v1, replace = c(`Reference area` = "Reference_area", `Frequency of observation` = "Freq_of_obs_el", `Unit of measure` = "Unit_of_measure_el", `Educational attainment level` = "Edu_attainment_lvl", "OBS_VALUE" = "OBS_VALUE_EL"))

safety_v2 <- rename(safety_v1, replace = c(`Reference area` = "Reference_area", `Frequency of observation` = "Freq_of_obs_sfty", `Unit of measure` = "Unit_of_measure_sfty", "Measure" = "Measure_safety", "OBS_VALUE" = "OBS_VALUE_SAFETY", "MEASURE" = "MEASURE_SAFETY"))

social_support_or_lack_v2 <- rename(social_support_or_lack_v1, replace = c(`Reference area` = "Reference_area", `Unit of measure` = "Unit_of_measure_social", "Measure" = "Measure_social", "OBS_VALUE" = "OBS_VALUE_SOCIAL", "MEASURE" = "MEASURE_SOCIAL"))

lonely_v2 <- rename(lonely_v1, replace = c(`Reference area` = "Reference_area", "OBS_VALUE" = "OBS_VALUE_LONELY", "Measure" = "Measure_lonely", "MEASURE" = "MEASURE_LONELY"))

satisfaction_life_rels_v2 <- rename(satisfaction_life_rels_v1, replace = c(`Reference area` = "Reference_area", "OBS_VALUE" = "OBS_VALUE_SAT", "Measure" = "Measure_sat", "MEASURE" = "MEASURE_SAT"))

```

```{r}
satisfaction_life_rels_v2[1:2,]
```


drop columns not anticipated to be needed or subset only the columns I will require


```{r}
# Columns to keep

phs_columns_to_keep <- c("REF_AREA", "Reference_area", "TIME_PERIOD", "OBS_VALUE_PHS", "Health_status", "HEALTH_STATUS")
el_columns_to_keep <- c("REF_AREA", "Reference_area", "TIME_PERIOD", "OBS_VALUE_EL", "Edu_attainment_lvl", "ATTAINMENT_LEV")
safety_columns_to_keep <- c("REF_AREA", "Reference_area", "TIME_PERIOD", "OBS_VALUE_SAFETY", "Measure_safety", "MEASURE_SAFETY")
social_columns_to_keep <- c("REF_AREA", "Reference_area", "TIME_PERIOD", "OBS_VALUE_SOCIAL", "Measure_social", "MEASURE_SOCIAL")
lonely_columns_to_keep <- c("REF_AREA", "Reference_area", "TIME_PERIOD", "OBS_VALUE_LONELY", "Measure_lonely", "MEASURE_LONELY")
satisfaction_columns_to_keep <- c("REF_AREA", "Reference_area", "TIME_PERIOD", "OBS_VALUE_SAT", "Measure_sat", "MEASURE_SAT")

phs_v3 <- subset(phs_v2, select = phs_columns_to_keep)
el_v3 <- subset(el_v2, select = el_columns_to_keep)
safety_v3 <- subset(safety_v2, select = safety_columns_to_keep)
social_support_or_lack_v3 <- subset(social_support_or_lack_v2, select = social_columns_to_keep)
lonely_v3 <- subset(lonely_v2, select = lonely_columns_to_keep)
satisfaction_life_rels_v3 <- subset(satisfaction_life_rels_v2, select = satisfaction_columns_to_keep)

```


```{r}

phs_v3

el_v3

safety_v3

social_support_or_lack_v3

lonely_v3

satisfaction_life_rels_v3

```




Pivot all data sets prior to merging them.

```{r}

phs_pivoted <- phs_v3 %>% 
  pivot_wider(
    id_cols = c("REF_AREA", "Reference_area", "TIME_PERIOD"), 
    names_from = c("HEALTH_STATUS"),
    names_prefix = "health_status_",
    values_from = "OBS_VALUE_PHS"
    )

phs_pivoted

```


```{r}

el_pivoted <- el_v3 %>% 
  pivot_wider(
    id_cols = c("REF_AREA", "Reference_area", "TIME_PERIOD"), 
    names_from = c("Edu_attainment_lvl"),
    values_from = "OBS_VALUE_EL"
    )


el_pivoted

```




```{r}

safety_pivoted <- safety_v3 %>% 
  pivot_wider(
    id_cols = c("REF_AREA", "Reference_area", "TIME_PERIOD"), 
    names_from = c("Measure_safety"),
    values_from = "OBS_VALUE_SAFETY"
    )


safety_pivoted

```

```{r}

social_support_or_lack_pivoted <- social_support_or_lack_v3 %>% 
  pivot_wider(
    id_cols = c("REF_AREA", "Reference_area", "TIME_PERIOD"), 
    names_from = c("Measure_social"),
    values_from = "OBS_VALUE_SOCIAL"
    )

social_support_or_lack_pivoted

```


```{r}

lonely_pivoted <- lonely_v3 %>% 
  pivot_wider(
    id_cols = c("REF_AREA", "Reference_area", "TIME_PERIOD"), 
    names_from = c("Measure_lonely"),
    values_from = "OBS_VALUE_LONELY"
    )

lonely_pivoted

```


```{r}

satisfaction_life_rels_pivoted <- satisfaction_life_rels_v3 %>% 
  pivot_wider(
    id_cols = c("REF_AREA", "Reference_area", "TIME_PERIOD"), 
    names_from = c("Measure_sat"),
    values_from = "OBS_VALUE_SAT"
    )

satisfaction_life_rels_pivoted

```



Merge all 6 data sets


```{r}

phs_el <- merge(
  phs_pivoted,
  el_pivoted,
  by = c("REF_AREA", "Reference_area", "TIME_PERIOD"),
  all = TRUE
)

phs_el

```

```{r}

phs_el_safety <- merge(
  phs_el,
  safety_pivoted,
  by = c("REF_AREA", "Reference_area", "TIME_PERIOD"),
  all = TRUE
)

phs_el_safety

```


```{r}

phs_el_safety_social <- merge(
  phs_el_safety,
  social_support_or_lack_pivoted,
  by = c("REF_AREA", "Reference_area", "TIME_PERIOD"),
  all = TRUE
)

phs_el_safety_social

```

```{r}

phs_el_safety_social_lonely <- merge(
  phs_el_safety_social,
  lonely_pivoted,
  by = c("REF_AREA", "Reference_area", "TIME_PERIOD"),
  all = TRUE
)

phs_el_safety_social_lonely

```

```{r}

phs_el_safety_social_lonely_satisfaction <- merge(
  phs_el_safety_social_lonely,
  satisfaction_life_rels_pivoted,
  by = c("REF_AREA", "Reference_area", "TIME_PERIOD"),
  all = TRUE
)

phs_el_safety_social_lonely_satisfaction

```

Use fill from tidyr to fill, up and down, the lonely data

```{r}

phs_el_safety_social_lonely_satisfaction_fill <- phs_el_safety_social_lonely_satisfaction |>
  group_by(Reference_area) |>
  fill(`Feeling lonely`, .direction = "updown") |>
  ungroup()

phs_el_safety_social_lonely_satisfaction_fill

```

```{r}

phs_el_safety_social_lonely_satisfaction_filled <- phs_el_safety_social_lonely_satisfaction_fill |>
  group_by(Reference_area) |>
  fill(`Satisfaction with personal relationships`, .direction = "updown") |>
  ungroup()

phs_el_safety_social_lonely_satisfaction_filled

```


```{r}

wellbeing_df <- phs_el_safety_social_lonely_satisfaction_filled |>
  group_by(Reference_area) |>
  fill(`Life satisfaction`, .direction = "updown") |>
  ungroup()

wellbeing_df

```

Final version of the dataset to be used in the shiny app.

```{r}

wellbeing_df %>% view()
```

```{r}

```

Histogram of wellbeing's "feeling lonely" column.

```{r}
hist(wellbeing_df$`Feeling lonely`, xlab="feeling lonely")
```
Inspect "Feeling lonely" column and the class of the dataframe. 

```{r}

sort(unique(wellbeing_df$`Feeling lonely`))


class(df)
```
Max of "Feeling lonely" column. 

```{r}
max(wellbeing_df$`Feeling lonely`, na.rm = TRUE)
```
inspect the dataframe.

```{r}
wellbeing_df %>% view()

```

rename columns in wellbeing data.

```{r}

wellbeing_df_rnmd <- rename(wellbeing_df, replace = c(`Upper secondary or post-secondary non-tertiary education` = "upper_secondary_or_post_secondary_not_tertiary_education", `Tertiary education` = "tertiary_education", `Below upper secondary education` = "below_upper_secondary_education", `Motor vehicle theft` = "motor_vehicle_theft", `Mortality from transport accidents` = "mortality_from_transport_accidents", `Intentional homicides` = "intentional_homicides", `Social support` = "social_support", `Lack of social support` = "lack_of_social_support", `Feeling lonely` = "feeling_lonely", `Life satisfaction` = "life_satisfaction", `Satisfaction with personal relationships` = "satisfaction_with_personal_relationships"))

```


```{r}
wellbeing_df_rnmd
```

Omit all NA values in wellbeing dataset and creating a csv for the dropped dataset.

```{r}

wellbeing_df_dropped <- na.omit(wellbeing_df_rnmd)
wellbeing_df_dropped

write.csv(wellbeing_df_dropped, file = "../data/wellbeing_df_dropped.csv")

```

Subset the dataframe to reflect only the columns I want to use for my heatmap. Find the correlation between the variables. Reformate that data by melting it. Create a heatmap using ggplot2.

```{r}

the_values <- wellbeing_df_dropped[, c("life_satisfaction", "feeling_lonely", "social_support", "intentional_homicides")]

data <- cor(the_values)

what_what <- melt(data)

ggplot(what_what, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  labs(title = "I'm confused",
       x = "var1",
       y = "var2") +
  scale_fill_gradient2(low = "yellow", high = "red",
                       limit = c(-1,1), name="value") +
    geom_text(aes(Var2, Var1, label = round(value, digits = 3)), size = 3)

```


```{r}


```

```{r}


  
```


```{r}



```

